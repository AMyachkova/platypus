{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization loops\n",
    "\n",
    "During this lesson, we'll learn how to use an *optimizer* to iteratively explore our ansatz's parameterized quantum states. Generally, requires us to:\n",
    "\n",
    "- Define a *cost function* $C(\\vec\\theta)$. This is a problem-specific function that defines the problem's goal for the optimizer to minimize (or maximize)\n",
    "- Pass the cost function output to a classical optimzer to evaluate the next parameters needed, until our optimizer converges on an answer\n",
    "- We'll also explore how to suppress and mitigate noise with Qiskit Runtime primitives (and the speed vs accuracy tradeoffs to do so).\n",
    "\n",
    "\n",
    "![Optimzation Loop](optimzation.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Functions\n",
    "\n",
    "Generally, cost functions are used to describe a problem's goal, and how well a trial state is performing with respect to the goal. This definition can be applied to examples across chemistry, machine learning, finance, optimization, etc.\n",
    "\n",
    "Let's use a simple example to illustrate this: finding the ground state of a system. Our goal is to minimize is the expectation value for the observable representing energy (*Hamiltonian* $\\hat{\\mathcal{H}}$):\n",
    "\n",
    "$$\n",
    "\\min_{\\vec\\theta} \\langle\\psi(\\vec\\theta)|\\hat{\\mathcal{H}}|\\psi(\\vec\\theta)\\rangle\n",
    "$$\n",
    "\n",
    "We can use the [_Estimator_ primitive](https://github.com/qiskit-community/prototype-zne/blob/main/docs/tutorials/0-estimator.ipynb) to evaluate the expectation value, and pass this value to an optimizer to minimize. If the optimization is successful, it will return a set of optimal parameter values $\\vec\\theta^*$, out of which we will be able to construct the _proposed solution state_ $|\\psi(\\vec\\theta^*)\\rangle$, and compute the observed expectation value as $C(\\vec\\theta^*)$.\n",
    "\n",
    "Notice how we will only be able to minimize the cost function for the limited set of states that we are considering. This leads us to two separate possiblities:\n",
    "\n",
    "- **Our ansatz does not define the solution state across the search space.** If this is the case, our optimizer will never find the solution, and we need to experiment with other ansatz that might able to represent our search space more accurately.\n",
    "- **Our optimizer is unable to find this valid solution**: Optimization can be globally defined and locally defined. We'll explore what this means in the later section.\n",
    "\n",
    "All in all, we will be performing a classical optimization loop but relaying the evaluation of the cost function to a quantum computer. From this perspective, one could think of the optimization as a purely classical endeavor where we call some _black-box quantum oracle_ each time the optimizer needs to evaluate the cost function."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "gloss": {
        "bias": {
         "text": "A systematic drift in the measured quantities, usually caused by errors.",
         "title": "Bias"
        },
        "overhead": {
            "text": "Extra costs introduced by new techniques, relative to a base implementation.",
            "title": "Overhead"
        }
   },
   "source": [
    "## Measurement Strategy: Speed vs Accuracy\n",
    "\n",
    "As mentioned, we using a noisy quantum computer as a *black-box oracle*, where noise can make the retrieved values non-deterministic, leading to random fluctuations which, in turn, will harm —or even completely prevent— convergence of certain optimizers to a proposed solution. This is a general problem that we must address as we incrementally progress towards quantum advantage:\n",
    "\n",
    "![Advantage](path_to_quantum_advantage.png)\n",
    "\n",
    "We can use Qiskit Runtime Primitive's error suppression and error mitigation options to address noise:\n",
    "\n",
    "### Error Suppression\n",
    "\n",
    "[Error suppression](https://qiskit.org/documentation/partners/qiskit_ibm_runtime/how_to/error-suppression.html) are techniques that optimize and transform your circuit at the point of compilation to minimize errors. This is the most basic error handling technique. Error suppression typically results in some classical pre-processing [overhead](gloss:overhead) to your overall runtime. Therefore, it is important to achieve a balance between perfecting your results and ensuring that your job completes in a reasonable amount of time.\n",
    "\n",
    "Primitives let you employ error suppression techniques by setting the `optimization_level` option and by choosing advanced transpilation options.\n",
    "\n",
    "### Error Mitigation\n",
    "\n",
    "[Error mitigation](https://qiskit.org/documentation/partners/qiskit_ibm_runtime/how_to/error-mitigation.html) are techniques that allow users to mitigate circuit errors by modeling the device noise at the time of execution. This typically results in quantum pre-processing overhead related to model training, and classical post-processing overhead to mitigate errors in the raw results by using the generated model. \n",
    "\n",
    "The `resilience_level` specifies how much resilience to build against errors. Higher levels generate more accurate results, at the expense of longer processing times due to quantum sampling overhead. Resilience levels can be used to configure the cost/accuracy trade-off when applying error mitigation to your primitive query. \n",
    "\n",
    "When implementing any error mitigation technique, we expect the [bias](gloss:bias) in our results to be reduced with respect to the previous, unmitigated, bias, in some cases even disappearing. However, this comes at a cost. As we reduce the bias in our estimated quantities, the statistical variability will increase (that is, variance), which we can account for by further increasing the number of shots per circuit in our sampling process. This will introduce overhead beyond that needed to reduce the bias, therefore it is not done by default. The user can easily opt in to this behavior by adjusting the amount of shots per circuit in run_options.\n",
    "\n",
    "![Bias Variance Tradeoff](bias_variance_trade_off.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating an expectation value, using Error Mitigation and Error Suppresion\n",
    "\n",
    "Here's how we calculate an expectation value. This happens multiple times across an optimization loop, but we've kept the example simple to show error mitigation and suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ideal\n",
    "\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService, Session, Estimator, Options\n",
    "from qiskit.circuit.library import TwoLocal\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "\n",
    "# Setup service\n",
    "service = QiskitRuntimeService()\n",
    "\n",
    "# Define operator, ansatz, and theta parameters\n",
    "operator = SparsePauliOp.from_list([(\"II\", 1), (\"IZ\", 2), (\"XI\", 3)])\n",
    "ansatz = TwoLocal(2, rotation_blocks=['rz', 'ry'], entanglement_blocks='cx', entanglement='linear', reps=1)\n",
    "theta = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "# Results for benchmark\n",
    "results = {}\n",
    "\n",
    "with Session(service=service, backend=\"ibmq_qasm_simulator\") as session:\n",
    "    estimator = Estimator(session=session)\n",
    "    job = estimator.run(circuits=[ansatz], observables=[operator], parameter_values=[theta])\n",
    "    estimated_value_operator = job.result()\n",
    "    session.close()\n",
    "\n",
    "ideal = estimated_value_operator.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.providers.fake_provider import FakeManila\n",
    "from qiskit_aer.noise import NoiseModel\n",
    "\n",
    "options = Options()\n",
    "# Create noise model from the backend to demonstrate error mitigation and suppression\n",
    "fake_backend = FakeManila()\n",
    "noise_model = NoiseModel.from_backend(fake_backend)\n",
    "\n",
    "# Set options to include the noise model\n",
    "options = Options()\n",
    "options.simulator = {\n",
    "    \"noise_model\": noise_model,\n",
    "    \"basis_gates\": fake_backend.configuration().basis_gates,\n",
    "    \"coupling_map\": fake_backend.configuration().coupling_map,\n",
    "    \"seed_simulator\": 42\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "with Session(service=service, backend=\"ibmq_qasm_simulator\") as session:\n",
    "    for suppression_level in range(0, 4):\n",
    "        for mitigation_level in range(0, 4):\n",
    "\n",
    "            options.optimization_level = suppression_level\n",
    "            options.resilience_level = mitigation_level\n",
    "            estimator = Estimator(session=session, options=options)\n",
    "            job = estimator.run(circuits=[ansatz], observables=[operator], parameter_values=[theta])\n",
    "            estimated_value_operator = job.result()\n",
    "            \n",
    "            \n",
    "            results.append({\n",
    "                'optimization_level': suppression_level,\n",
    "                'resilience_level': mitigation_level,\n",
    "                'expectation_value': estimated_value_operator.values[0]\n",
    "            })\n",
    "           \n",
    "    session.close()\n",
    "\n",
    "print(f\"\"\"Ideal result {ideal}\"\"\")\n",
    "for result in results:\n",
    "    print(f\"\"\"Suppression {result['optimization_level']}, Mitigation {result['resilience_level']}: {result['expectation_value']}\"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstraping Optimization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Bootstrapping*, or setting the initial value for parameters $\\vec\\theta$ based on a prior optimization, can help our optimzer converge on a solution faster. We refer to these as the _initial point_ $\\vec\\theta_0$, and $|\\psi(\\vec\\theta_0)\\rangle = U_V(\\vec\\theta_0)|\\rho\\rangle$ as the _initial state_.\n",
    "\n",
    "This initial state differs from our *reference state* $|\\rho\\rangle$, as the former focuses on initial parameters set during our optimization loop, while the latter focuses on using known \"reference\" solutions. They may coincide if $U_V(\\vec\\theta_0) \\equiv I$ (i.e. the identity operation)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local and Global Optimizers\n",
    "\n",
    "There are two main types of optimizers:\n",
    "\n",
    "### Local Optimizers\n",
    "\n",
    "Local optimizers look for a point that minimizes the cost function starting at an initial point(s) $C(\\vec{\\theta_0})$ and moving to different points based on what they see in the region they happen to be at on successive iterations. That implies that the convergence of these algorithms will usually be fast, but can heavily dependent on the initial point. \n",
    "\n",
    "Some of these algorithms use the _gradient_ of the cost function $\\nabla C(\\vec{\\theta})$ (or an approximation) to choose the next set of values for the parameters $\\vec{\\theta}$ while others are based on completely different techniques. Local optimizers are unable to see beyond the region were they are evaluating, and turn out to be especially vulnerable to local minima, reporting convergence when they find one, ignoring other states with more favorable evaluations.\n",
    "\n",
    "### Global Optimizers\n",
    "\n",
    "Global optimizers look for the point that minimizes the cost function over several regions of its domain (i.e. non-local), evaluating it iteratively (i.e. iteration $i$) over a spread (i.e. indexed $j$) of parameter values $\\vec{\\theta}_{i,j}$. \n",
    "\n",
    "This makes them less susceptible to local minima and somewhat independent of initialization, but also significantly slower to converge to a proposed solution. For this reason, they are often times combined with local optimizers, where one would warm start the optimization globally, and refine the convergence locally.\n",
    "\n",
    "In fact, the loss landscape can be quite complicated, as shown in hills and valleys of the example below. The optimization method navigates us around the loss landscape, searching for the minimum, as shown by the black points and lines. we can see that two of the three searches end up in a local landscape minimum, rather than a global one. \n",
    "\n",
    "![Loss Landscape](loss-landscape.png)\n",
    "\n",
    "Generally the optimization methods can be categorised into two groups: gradient-based and gradient-free methods. To determine an optimal solution, gradient-based methods identify an extreme point at which the gradient is equal to zero. A search direction is selected and the searching direction is determined by the derivative of the loss function. The main disadvantages of this type of optimization are the convergence speed can be very slow and there is no guarantee to achieve the optimal solution. \n",
    "\n",
    "When derivative information is unavailable or impractical to obtain (e.g. when the loss function is expensive to evaluate or somewhat noisy), gradient-free methods can be very useful. Such optimisation techniques are robust to find the global optima, while the gradient-based methods tend to converge into local optima. However, gradient-free methods require higher computational capacities, especially for the problems with high-dimensional search spaces.\n",
    "\n",
    "![Barren Plateaus](barren-plateaus.png)\n",
    "\n",
    "Despite what type of optimization method is used, if the loss landscape is fairly flat, it can be difficult for the method to determine which direction to search. This situation is called a _[barren plateau](gloss:barren-plateaus),_ where the loss loss landscape becomes increasingly flat (and thus hard to determine the direction to the minimum). For a wide class of reasonable parameterized quantum circuits, the probability that the gradient along any reasonable direction is non-zero to some fixed precision is exponentially small as a function of the number of qubits."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this is still an area of active research, we have a few recommendations:\n",
    "\n",
    "- **Bootstrapping** helps the optimization loop avoid getting stuck in a parameter space where the gradient is small.\n",
    "- **Experimenting with hardware-efficient ansatz**: as we're using a noisy quantum system as a *black-box oracle*, the _quality_ of those evaluations will affect the performance of the optimizer. Using hardware-efficent ansatz, such as [`EfficientSU2`](https://qiskit.org/documentation/stubs/qiskit.circuit.library.EfficientSU2.html), could avoid producing exponentially small gradients.\n",
    "- **Experimenting with error suppression and error mitigation**: the Qiskit Runtime Primitives offer a simple interface to experiment with a variety of `optimization_level`s and `resilience_setting`s respectively. This can reduce the impact of noise and make the optimization process more efficient.\n",
    "- **Experimenting with gradient-free optimizers**: Unlike gradient-based optimization algorithms, `COBYLA` does not rely on gradient information to optimize the parameters, and can avoid the barren plateau."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this lesson, you learned how to define your optimization loop:\n",
    "\n",
    "- Create a cost function\n",
    "- Experimented with error mitigation and suppression\n",
    "- Bootstrapped your parameters\n",
    "- Explored optimzers and how to avoid barren plataeus\n",
    "\n",
    "Our high-level variational workload is complete:\n",
    "\n",
    "![Optimization Loop](circuit_optimization.png)\n",
    "\n",
    "Next, we'll explore specific variational algorithms with this framework in mind"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
